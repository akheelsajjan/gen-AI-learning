{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aece321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Mini-RAG with REAL embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b32e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    {\"id\": \"doc1\", \"text\": \"Python is a programming language.\"},\n",
    "    {\"id\": \"doc2\", \"text\": \"The sky is blue during the day.\"},\n",
    "    {\"id\": \"doc3\", \"text\": \"Dogs are loyal animals.\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e97cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is A?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eddf7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import math\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e321d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embeddings = {}\n",
    "\n",
    "for doc in documents:\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        input=doc[\"text\"]\n",
    "    )\n",
    "    doc_embeddings[doc[\"id\"]] = response.data[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39071853",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=query\n",
    ").data[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0613d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    dot = sum(x * y for x, y in zip(a, b))\n",
    "    mag_a = math.sqrt(sum(x * x for x in a))\n",
    "    mag_b = math.sqrt(sum(y * y for y in b))\n",
    "    return dot / (mag_a * mag_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae226aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_docs = []\n",
    "\n",
    "for doc in documents:\n",
    "    score = cosine_similarity(\n",
    "        query_embedding,\n",
    "        doc_embeddings[doc[\"id\"]]\n",
    "    )\n",
    "    scored_docs.append((score, doc[\"text\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "def71c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_docs.sort(reverse=True, key=lambda x: x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d7cf5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.653 → Python is a programming language.\n",
      "0.091 → Dogs are loyal animals.\n",
      "0.076 → The sky is blue during the day.\n"
     ]
    }
   ],
   "source": [
    "for score, text in scored_docs:\n",
    "    print(f\"{score:.3f} → {text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dd3ed4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved document:\n",
      "Python is a programming language.\n"
     ]
    }
   ],
   "source": [
    "top_doc = scored_docs[0][1]\n",
    "print(\"\\nRetrieved document:\")\n",
    "print(top_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff3350f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fe85808",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc = scored_docs[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0c65940",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are answering a question using ONLY the context below.\n",
    "If the answer is not in the context, say \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{top_doc}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfc623d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9590295d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "answer = response.choices[0].message.content\n",
    "print(\"Answer:\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbfb4bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "# Embeddings beat keywords because they capture semantic meaning, not exact words.\n",
    "# Embeddings beat keywords because they retrieve by meaning, not by word match\n",
    "# Similar meanings → similar vectors\n",
    "# Zero word overlap still works\n",
    "# Embeddings matter because they enable semantic search, retrieving text by meaning rather than exact words, \n",
    "# even with zero word overlap.\n",
    "\n",
    "\n",
    "\n",
    "# Cosine understanding\n",
    "# Cosine similarity measures how aligned two meanings are, ignoring length.\n",
    "#Cosine similarity measures:\n",
    "# --Directional alignment, not magnitude, --Whether two vectors point the same way in meaning space\n",
    "# Why this matters: Sentence length doesn’t matter, Extra words don’t distort similarity\n",
    "\n",
    "\n",
    "\n",
    "# Chunking\n",
    "# Chunking prevents meaning dilution,  allows precise retrieval of facts.\n",
    "# Preserves local meaning, Makes retrieval precise, Enables fact-level search\n",
    "\n",
    "\n",
    "# RAG Failure \n",
    "# Wrong chunks are retrieved, Right chunks are split badly, Query is vague, Prompt allows guessing\n",
    "# RAG fails silently when retrieval is wrong and the model is allowed to guess.\n",
    "\n",
    "# RAG debug it logically\n",
    "# Always debug RAG in this order: query → retrieved chunks → answer.\n",
    "# Debug order must always be:\n",
    "# Query (is it clear?)\n",
    "# Retrieved chunks (are they relevant?)\n",
    "# Prompt constraints (is guessing allowed?)\n",
    "# Final answer\n",
    "\n",
    "#How retrieval works?\n",
    " # Retrieval works by chunking documents, embedding them and the query using the same model,\n",
    " # then ranking chunks by cosine similarity to the query vector.\n",
    "\n",
    "\n",
    "# More context is not always better.\n",
    "# Correct context is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aa2439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
