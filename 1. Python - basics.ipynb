{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f04b8689",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\"You\", \"are\", \"an\", \"AI\", \"assistant\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18bc6917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an', 'AI', 'assistant']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:3]\n",
    "tokens[2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c142cad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'system',\n",
       " 'content': 'You are a helpful assistant',\n",
       " 'temperature': 0.7}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are a helpful assistant\"\n",
    "}\n",
    "prompt[\"role\"]\n",
    "prompt[\"temperature\"] = 0.7\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1244b793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explain embeddings'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert\"},\n",
    "    {\"role\": \"user\", \"content\": \"Explain embeddings\"}\n",
    "]\n",
    "messages[1][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a389776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system => You are an expert\n",
      "user => Explain embeddings\n"
     ]
    }
   ],
   "source": [
    "for msg in messages:\n",
    "    print(msg[\"role\"], \"=>\", msg[\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e25cf1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You are an expert', 'Explain embeddings']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents = [msg[\"content\"] for msg in messages]\n",
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60559eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Explain embeddings']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents = [msg[\"content\"] for msg in messages  if msg[\"role\"] == \"user\"]\n",
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08c3d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    {\"id\": 1, \"text\": \"LLMs predict the next token\", \"source\": \"blog\"},\n",
    "    {\"id\": 2, \"text\": \"Embeddings convert text to vectors\", \"source\": \"paper\"},\n",
    "    {\"id\": 3, \"text\": \"RAG combines retrieval and generation\", \"source\": \"notes\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75e6c137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMs predict the next token\n",
      "Embeddings convert text to vectors\n",
      "RAG combines retrieval and generation\n"
     ]
    }
   ],
   "source": [
    "#A list of only text values\n",
    "for item in documents:\n",
    "    print(item[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55fb24cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LLMs predict the next token', 'Embeddings convert text to vectors']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A list of texts where source is \"paper\" or \"blog\"\n",
    "contents = [\n",
    "              msg[\"text\"]\n",
    "              for msg in documents\n",
    "              if msg[\"source\"] in (\"paper\", \"blog\" )]\n",
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f3960c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blog: LLMs predict the next token']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A new list where each item looks like:\n",
    "new_list = [[f'{d[\"source\"]}: {d[\"text\"]}' for d in documents][0]]\n",
    "new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae42439c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explain RAG at a beginner level.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic = \"RAG\"\n",
    "level = \"beginner\"\n",
    "\n",
    "prompt = f\"Explain {topic} at a {level} level.\"\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "82d0d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name = \"Akheel\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an expert AI assistant.\n",
    "\n",
    "User:\n",
    "Name: {user_name}\n",
    "Goal: Learn Generative AI\n",
    "\n",
    "Task:\n",
    "Explain embeddings in simple terms with one example.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e3c66b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- LLMs predict the next token\\n- Embeddings convert text to vectors\\n- RAG combines retrieval and generation'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"\\n\".join(\n",
    "    f\"- {d['text']}\" for d in documents\n",
    ")\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01a6ffad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou are a knowledgeable AI assistant.\\n\\nUse the following context:\\n- LLMs predict the next token\\n- Embeddings convert text to vectors\\n- RAG combines retrieval and generation\\n\\nQuestion:\\nExplain how these concepts connect together.\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a knowledgeable AI assistant.\n",
    "\n",
    "Use the following context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "Explain how these concepts connect together.\n",
    "\"\"\"\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c57c49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[blog] LLMs predict the next token\\n[paper] Embeddings convert text to vectors\\n[notes] RAG combines retrieval and generation'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[blog] LLMs predict the next token\n",
    "doc_context = \"\\n\".join(\n",
    "    f\"[{d['source']}] {d['text']}\" for d in documents\n",
    ")\n",
    "\n",
    "doc_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7d9deb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou are a GenAI teacher.\\nHere is some context:\\n[blog] LLMs predict the next token\\n[paper] Embeddings convert text to vectors\\n[notes] RAG combines retrieval and generation\\nQuestion:\\nExplain how these concepts under 120 word.\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a multiline prompt that:\n",
    "#Sets the system role as an expert GenAI teacher\n",
    "#Injects the context\n",
    "#Asks the model to explain everything in under 120 words\n",
    "#Store it in a variable called final_prompt.\n",
    "system_role = 'GenAI teacher'\n",
    "final_prompt = f\"\"\"\n",
    "You are a {system_role}.\n",
    "Here is some context:\n",
    "{doc_context}\n",
    "Question:\n",
    "Explain how these concepts under 120 word.\n",
    "\"\"\"\n",
    "final_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "686d72a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "SYSTEM ROLE:\n",
    "You are an expert Generative AI teacher.\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "TASK:\n",
    "Explain how these concepts connect together.\n",
    "Keep it under 120 words.\n",
    "\"\"\"\n",
    "\n",
    "with open(\"prompt_template.txt\", \"w\") as f:\n",
    "    f.write(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c029f068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSYSTEM ROLE:\\nYou are an expert Generative AI teacher.\\n\\nCONTEXT:\\n{context}\\n\\nTASK:\\nExplain how these concepts connect together.\\nKeep it under 120 words.\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"prompt_template.txt\", \"r\") as f:\n",
    "    prompt_template = f.read()\n",
    "\n",
    "prompt_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e89810c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SYSTEM ROLE:\n",
      "You are an expert Generative AI teacher.\n",
      "\n",
      "CONTEXT:\n",
      "[blog] LLMs predict the next token\n",
      "[paper] Embeddings convert text to vectors\n",
      "[notes] RAG combines retrieval and generation\n",
      "\n",
      "TASK:\n",
      "Explain how these concepts connect together.\n",
      "Keep it under 120 words.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_prompt = prompt_template.format(\n",
    "    context=doc_context\n",
    ")\n",
    "\n",
    "print(final_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1132eec",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a7b4caade3b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m response = client.chat.completions.create(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\_client.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             raise OpenAIError(\n\u001b[0m\u001b[0;32m    138\u001b[0m                 \u001b[1;34m\"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             )\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1649815f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
